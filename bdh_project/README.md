# BDH Track B: Narrative Consistency Classification

**Stateful Recurrent Memory for Long-Context Reasoning**

This project implements a **Baby Dragon Hatchling (BDH)** architecture to detect narrative inconsistencies in long novels (100k+ words). It leverages a stateful **œÅ-matrix (Hebbian memory)** to track character traits and detect contradictions.

## üöÄ Quick Start

### Local Machine
```bash
cd bdh_project
pip install -r requirements.txt

# Fast Mode (Recommended for testing, ~25 min)
python main.py --small

# High Accuracy Mode (Recommended for final result, ~3.5 hrs)
python main.py --small --mode streaming

# K-Fold + Multi-Checkpoint (Best accuracy for cached mode)
python main.py --small --mode cached --improvise

# Ensemble Mode (Combine all 3 hypotheses)
python main.py --small --mode cached --ensemble
```

---

## ‚ö° Processing Modes

### 1. Cached Mode (Default)
**Command**: `python main.py --mode cached`
**Speed**: ~25 minutes total
**Method**: Pre-computes novel states once, compares final states.
- **Phase 0**: Stream 2 novels ‚Üí Save œÅ_novel states (~10 min)
- **Phase 1**: For each backstory ‚Üí `velocity = 1 - cosine(œÅ_backstory, œÅ_novel)` (~5 min)
- **Accuracy**: ~70% (Loses temporal resolution)

### 2. Streaming Mode (Recommended)
**Command**: `python main.py --mode streaming`
**Speed**: ~3.5 hours total
**Method**: Streams full novel for *every* calibration example.
- **Calibration**: Tracks velocity chapter-by-chapter: `max(||œÅ‚ÇÅ-œÅ‚ÇÄ||, ||œÅ‚ÇÇ-œÅ‚ÇÅ||, ...)`
- **Inference**: Uses cached states (Instant!)
- **Accuracy**: **~80%** (Captures temporal dynamics)

### 3. Perturbation Mode
**Command**: `python main.py --perturbation`
**Speed**: ~3.5 hours total
**Method**: Measures trajectory divergence.
- `velocity = ||process(novel) - process(backstory + novel)||`
- Tests if knowing the backstory changes how the model interprets the novel.

### 4. Improvise Mode (K-Fold + Multi-Checkpoint)
**Command**: `python main.py --mode cached --improvise`
**Speed**: ~35 min (cached) or ~3.5 hrs (streaming)
**Method**: K-fold cross-validation for robust threshold.
- Splits 80 train examples into 4 folds (60 train / 20 val each)
- Uses median threshold across folds (reduces variance)
- For cached mode: Multi-checkpoint trajectories (25%, 50%, 75%, 100%)
- **Accuracy**: ~75-78% (cached) or ~82-85% (streaming)

### 5. Ensemble Mode (All 3 Hypotheses)
**Command**: `python main.py --mode cached --ensemble`
**Speed**: ~45 min (cached) or ~4 hrs (streaming)
**Method**: Combines all 3 hypotheses with majority vote:
- **A. Velocity-Based**: Track œÅ-matrix change rate
- **B. Embedding Divergence**: Measure drift from backstory embedding
- **C. Perplexity**: Backstory-conditioned perplexity on novel
- **Decision**: Majority vote (2/3 signals agree)

### 6. Fast Ensemble (Velocity + Divergence Only)
**Command**: `python main.py --mode cached --ensemble-fast`
**Speed**: ~30 min (cached)
**Method**: Skips slow perplexity computation:
- Uses only **Velocity (A)** and **Embedding Divergence (B)**
- Both must agree; velocity is tiebreaker

### 7. **Ultimate Mode: K-Fold + Ensemble (Best Accuracy)**
**Command**: `python main.py --mode cached --improvise --ensemble-fast`
**Speed**: ~35 min (cached)
**Method**: Combines the robustness of K-fold with ensemble prediction:
- **4-fold cross-validation** for robust threshold estimation
- **Multi-checkpoint trajectories** (25%, 50%, 75%, 100%)
- **Ensemble voting** (Velocity + Divergence) on each fold
- **Median thresholds** computed for both hypotheses
- **Expected Accuracy**: ~70-75% (cached)

---

## üìä Metrics

We support two distance metrics for velocity computation:

1. **Cosine Similarity (Default)**: `1 - cosine(œÅ_a, œÅ_b)`
   - **Why**: Normalized (0-2 range), ignores magnitude differences.
   - **Best for**: Comparing final states (Cached Mode).

2. **L2 Norm**: `||œÅ_a - œÅ_b||‚ÇÇ`
   - **Why**: Measures absolute magnitude of change.
   - **Best for**: Tracking spikes within a single stream (Streaming Mode).

---

## üìÇ Project Structure
```
bdh_project/
‚îú‚îÄ‚îÄ config/         # Model configs (4-layer vs 6-layer)
‚îú‚îÄ‚îÄ model/          # Recurrent BDH (Stateful œÅ-matrix)
‚îú‚îÄ‚îÄ metrics/        # Velocity tracking & calibration
‚îú‚îÄ‚îÄ inference/      # Wrapper with caching & perturbation support
‚îú‚îÄ‚îÄ utils/          # Data loading & tokenizer
‚îî‚îÄ‚îÄ main.py         # Unified pipeline (Cached/Streaming/Perturbation)
```

---

## üìà Performance Summary

| Mode | Flags | Time | Accuracy | Use Case |
|------|-------|------|----------|----------|
| **Cached** | `--mode cached` | ~25 min | ~70% | Fast iteration |
| **Cached + K-Fold** | `--improvise` | ~35 min | ~72-75% | Better accuracy |
| **Fast Ensemble** | `--ensemble-fast` | ~30 min | ~67% | Quick ensemble |
| **K-Fold + Ensemble** | `--improvise --ensemble-fast` | **~40 min** | **~70-75%** | **Best for cached** |
| **Streaming** | `--mode streaming` | ~3.5 hrs | ~80% | High accuracy |
| **Streaming + K-Fold** | `--mode streaming --improvise` | ~3.5 hrs | **~82-85%** | Best overall |

---

## üî¨ Technical Details

- **Tokenization**: Byte-level (vocab=256)
- **Damping**: 0.99 (prevents œÅ explosion)
- **RoPE**: Retained in latent space
- **Train/Val Split**: 60/20 (stratified), or K-Fold (4 folds) with `--improvise`
- **Metrics Output**: Accuracy, F1 Score, Confusion Matrix
